{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765c8d28-ce90-4f09-b92e-847d786089f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'audio-diffusion-pytorch-trainer'...\n",
      "remote: Enumerating objects: 1819, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 1819 (delta 0), reused 2 (delta 0), pack-reused 1814\u001b[K\n",
      "Receiving objects: 100% (1819/1819), 273.22 KiB | 4.48 MiB/s, done.\n",
      "Resolving deltas: 100% (1423/1423), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/archinetai/audio-diffusion-pytorch-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078c8d68-bcb7-4c3b-bb35-743c7f671618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r audio-diffusion-pytorch-trainer/requirements.txt (line 1)) (1.13.1+cu116)\n",
      "Collecting pytorch-lightning==1.7.7\n",
      "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hydra-colorlog\n",
      "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting auraloss\n",
      "  Downloading auraloss-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2023.2.17-py2.py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyloudnorm\n",
      "  Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Collecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich\n",
      "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.13.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting eng-to-ipa\n",
      "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ema-pytorch\n",
      "  Downloading ema_pytorch-0.2.1-py3-none-any.whl (4.4 kB)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.20.4-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audio-diffusion-pytorch==0.0.92\n",
      "  Downloading audio_diffusion_pytorch-0.0.92-py3-none-any.whl (20 kB)\n",
      "Collecting audio-encoders-pytorch\n",
      "  Downloading audio_encoders_pytorch-0.0.22-py3-none-any.whl (9.6 kB)\n",
      "Collecting audio-data-pytorch\n",
      "  Downloading audio_data_pytorch-0.0.19-py3-none-any.whl (22 kB)\n",
      "Collecting quantizer-pytorch\n",
      "  Downloading quantizer_pytorch-0.0.22-py3-none-any.whl (7.6 kB)\n",
      "Collecting difformer-pytorch\n",
      "  Downloading difformer_pytorch-0.0.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting a-transformers-pytorch\n",
      "  Downloading a_transformers_pytorch-0.0.10-py3-none-any.whl (9.5 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (1.24.2)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (6.0)\n",
      "Collecting data-science-types>=0.2\n",
      "  Downloading data_science_types-0.2.23-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops-exts>=0.0.3\n",
      "  Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting Click!=8.0.0,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (5.9.4)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (67.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (2.28.2)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.22.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycryptodomex\n",
      "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mutagen\n",
      "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from yt-dlp->-r audio-diffusion-pytorch-trainer/requirements.txt (line 8)) (2019.11.28)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets\n",
      "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.7\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.0.1\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting future>=0.16.0\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r audio-diffusion-pytorch-trainer/requirements.txt (line 13)) (2.14.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.1-py3-none-any.whl (24 kB)\n",
      "Collecting msgpack>=1.0\n",
      "  Downloading msgpack-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.0\n",
      "  Downloading scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.51.0\n",
      "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r audio-diffusion-pytorch-trainer/requirements.txt (line 15)) (5.1.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting texttable\n",
      "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pybcj>=0.6.0\n",
      "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting inflate64>=0.3.1\n",
      "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
      "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.0/379.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audio-encoders-pytorch->-r audio-diffusion-pytorch-trainer/requirements.txt (line 22)) (0.13.1+cu116)\n",
      "Collecting webdataset\n",
      "  Downloading webdataset-0.2.33-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tinytag\n",
      "  Downloading tinytag-1.8.1.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bidict\n",
      "  Downloading bidict-0.22.1-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (1.14.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r audio-diffusion-pytorch-trainer/requirements.txt (line 9)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r audio-diffusion-pytorch-trainer/requirements.txt (line 9)) (3.0.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.17.2\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r audio-diffusion-pytorch-trainer/requirements.txt (line 6)) (1.25.8)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r audio-diffusion-pytorch-trainer/requirements.txt (line 15)) (1.15.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (0.38.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.51.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.1-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r audio-diffusion-pytorch-trainer/requirements.txt (line 9)) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r audio-diffusion-pytorch-trainer/requirements.txt (line 9)) (2.8.2)\n",
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r audio-diffusion-pytorch-trainer/requirements.txt (line 15)) (2.21)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning==1.7.7->-r audio-diffusion-pytorch-trainer/requirements.txt (line 2)) (2.1.2)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, eng-to-ipa, audioread, future, pathtools, tinytag\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=51ba54049ec712e150378ab4f41a81b83612d72e1828e4d38a997bfdd6d41576\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for eng-to-ipa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for eng-to-ipa: filename=eng_to_ipa-0.0.2-py3-none-any.whl size=2822605 sha256=3ec67f81d9c66c05b0d7f9bb098b1fd022091f12b792b6ce168bed30f1d8874a\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/ab/07/fe6722f710d8ef8bd0ccb4eb689ef96f5552f3fc0c80c1aa9c\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23704 sha256=c1b87fd708b40aafb37d7dbaaedb2324bb07e87ffcc19064bfeb420fb0d72094\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/4b/39/c5f6c4ee93b43281dda4dab5ac5f2bdf9d11074d427493cd55\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=a5b89fee5e645d9ef312e50f604d22bd9918da5b091b669bdc09b8d16db15c24\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=9535872aff330486f2cb685bf44ce47a654c26318d0df682b1acf209c8f0269b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "  Building wheel for tinytag (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinytag: filename=tinytag-1.8.1-py3-none-any.whl size=35817 sha256=e6f8a792609ae6ff0329322be2fd4a1dfb7acd3586a6b215b77cc65b20b0f080\n",
      "  Stored in directory: /root/.cache/pip/wheels/9d/c7/89/b9411166ca17da9d7360d87950808c1258bfecb445efb82b4f\n",
      "Successfully built antlr4-python3-runtime eng-to-ipa audioread future pathtools tinytag\n",
      "Installing collected packages: tokenizers, texttable, tensorboard-plugin-wit, pyasn1, pathtools, msgpack, eng-to-ipa, brotli, braceexpand, appdirs, antlr4-python3-runtime, xxhash, werkzeug, websockets, urllib3, tqdm, tinytag, threadpoolctl, tensorboard-data-server, tenacity, smmap, setproctitle, rsa, regex, pyzstd, python-dotenv, pyppmd, pyDeprecate, pycryptodomex, pybcj, pyasn1-modules, protobuf, omegaconf, oauthlib, numpy, mutagen, multivolumefile, multidict, mdurl, markdown, llvmlite, lazy-loader, joblib, inflate64, grpcio, future, fsspec, frozenlist, filelock, einops, docker-pycreds, dill, data-science-types, colorlog, Click, cachetools, bidict, audioread, async-timeout, absl-py, yt-dlp, yarl, webdataset, torchmetrics, soxr, soundfile, sentry-sdk, scipy, quantizer-pytorch, pyarrow, py7zr, plotly, pandas, numba, multiprocess, markdown-it-py, hydra-core, google-auth, gitdb, ema-pytorch, einops-exts, difformer-pytorch, auraloss, aiosignal, scikit-learn, rich, responses, requests-oauthlib, pyloudnorm, pooch, hydra-colorlog, huggingface-hub, GitPython, audio-encoders-pytorch, aiohttp, wandb, transformers, librosa, google-auth-oauthlib, audio-diffusion-pytorch, audio-data-pytorch, tensorboard, datasets, a-transformers-pytorch, pytorch-lightning\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 a-transformers-pytorch-0.0.10 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 async-timeout-4.0.2 audio-data-pytorch-0.0.19 audio-diffusion-pytorch-0.0.92 audio-encoders-pytorch-0.0.22 audioread-3.0.0 auraloss-0.3.0 bidict-0.22.1 braceexpand-0.1.7 brotli-1.0.9 cachetools-5.3.0 colorlog-6.7.0 data-science-types-0.2.23 datasets-2.9.0 difformer-pytorch-0.0.6 dill-0.3.6 docker-pycreds-0.4.0 einops-0.6.0 einops-exts-0.0.4 ema-pytorch-0.2.1 eng-to-ipa-0.0.2 filelock-3.9.0 frozenlist-1.3.3 fsspec-2023.1.0 future-0.18.3 gitdb-4.0.10 google-auth-2.16.1 google-auth-oauthlib-0.4.6 grpcio-1.51.1 huggingface-hub-0.12.1 hydra-colorlog-1.2.0 hydra-core-1.3.1 inflate64-0.3.1 joblib-1.2.0 lazy-loader-0.1 librosa-0.10.0 llvmlite-0.39.1 markdown-3.4.1 markdown-it-py-2.1.0 mdurl-0.1.2 msgpack-1.0.4 multidict-6.0.4 multiprocess-0.70.14 multivolumefile-0.2.3 mutagen-1.46.0 numba-0.56.4 numpy-1.23.5 oauthlib-3.2.2 omegaconf-2.3.0 pandas-1.5.3 pathtools-0.1.2 plotly-5.13.0 pooch-1.6.0 protobuf-4.22.0 py7zr-0.20.4 pyDeprecate-0.3.2 pyarrow-11.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybcj-1.0.1 pycryptodomex-3.17 pyloudnorm-0.1.1 pyppmd-1.0.0 python-dotenv-0.21.1 pytorch-lightning-1.7.7 pyzstd-0.15.3 quantizer-pytorch-0.0.22 regex-2022.10.31 requests-oauthlib-1.3.1 responses-0.18.0 rich-13.3.1 rsa-4.9 scikit-learn-1.2.1 scipy-1.10.1 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 soundfile-0.12.1 soxr-0.3.3 tenacity-8.2.1 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 texttable-1.6.7 threadpoolctl-3.1.0 tinytag-1.8.1 tokenizers-0.13.2 torchmetrics-0.11.1 tqdm-4.64.1 transformers-4.26.1 urllib3-1.26.14 wandb-0.13.10 webdataset-0.2.33 websockets-10.4 werkzeug-2.2.3 xxhash-3.2.0 yarl-1.8.2 yt-dlp-2023.2.17\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r audio-diffusion-pytorch-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66088101-1d64-4eb0-9929-9cb17ac3f553",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: audio-diffusion-pytorch 0.0.92\n",
      "Uninstalling audio-diffusion-pytorch-0.0.92:\n",
      "  Successfully uninstalled audio-diffusion-pytorch-0.0.92\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting audio-diffusion-pytorch\n",
      "  Downloading audio_diffusion_pytorch-0.1.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audio-diffusion-pytorch) (0.13.1+cu116)\n",
      "Requirement already satisfied: einops>=0.6 in /usr/local/lib/python3.10/dist-packages (from audio-diffusion-pytorch) (0.6.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audio-diffusion-pytorch) (4.64.1)\n",
      "Collecting a-unet\n",
      "  Downloading a_unet-0.0.16-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: data-science-types>=0.2 in /usr/local/lib/python3.10/dist-packages (from audio-diffusion-pytorch) (0.2.23)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from audio-diffusion-pytorch) (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->audio-diffusion-pytorch) (4.5.0)\n",
      "Installing collected packages: a-unet, audio-diffusion-pytorch\n",
      "Successfully installed a-unet-0.0.16 audio-diffusion-pytorch-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall audio-diffusion-pytorch --yes\n",
    "!pip install audio-diffusion-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef5030-506d-45c0-bf86-89522b9d3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/archinetai/audio-diffusion-pytorch.git\n",
    "!pip uninstall audio_diffusion_pytorch --yes\n",
    "!pip install /workspace/audio-diffusion-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c34308-698c-446a-8724-93fa44bff190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/archinetai/a-unet.git\n",
    "!pip uninstall a_unet --yes\n",
    "!pip install /workspace/a-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce33b889-5f8e-495d-a116-d25b5302f063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './audio-diffusion-pytorch-trainer/.env': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm ./audio-diffusion-pytorch-trainer/.env\n",
    "!touch ./audio-diffusion-pytorch-trainer/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8713a99-ad61-4773-b9f1-3c6c49d2c6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line_to_env_file(file_path, line):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(line + '\\n')\n",
    "        \n",
    "file_path = './audio-diffusion-pytorch-trainer/.env'\n",
    "write_line_to_env_file(file_path, \"DIR_LOGS=/kaggle/working/logs\")\n",
    "write_line_to_env_file(file_path, \"DIR_DATA=/kaggle/working/data\")\n",
    "write_line_to_env_file(file_path, \"WANDB_API_KEY=aad9461926e43142945b4743738ef434a25a147e\")\n",
    "write_line_to_env_file(file_path, \"WANDB_PROJECT=audio-diffusion\")\n",
    "write_line_to_env_file(file_path, \"WANDB_ENTITY=tvergho1\")\n",
    "write_line_to_env_file(file_path, \"HYDRA_FULL_ERROR=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398cced5-b6e6-4836-8976-cf47ce890561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff52a7b-7279-4089-861b-749c80a61ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.8.1.tar.gz (759 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.6/759.6 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hjson\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ninja\n",
      "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.4)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.13.1+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.5.0)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.8.1-py3-none-any.whl size=765880 sha256=f17d9e01d6be09403c3f26fedaa24758420591fd190371addc40609218cf2d8c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/3b/f3/0d41f09dee0c141026b75113dad74a13f22356caeaf0c6e175\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: py-cpuinfo, ninja, hjson, pydantic, deepspeed\n",
      "Successfully installed deepspeed-0.8.1 hjson-3.1.0 ninja-1.11.1 py-cpuinfo-9.0.0 pydantic-1.10.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91402eab-1093-4355-b790-f2e3dc4a7314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile /workspace/audio-diffusion-pytorch-trainer/train_custom.py\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import dotenv\n",
    "import pytorch_lightning as pl\n",
    "from main import utils\n",
    "from omegaconf import DictConfig, open_dict\n",
    "from audio_data_pytorch import WAVDataset, AllTransform\n",
    "from audio_diffusion_pytorch import DiffusionModel\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichModelSummary, RichProgressBar\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import auraloss\n",
    "import librosa\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import wandb\n",
    "from audio_data_pytorch.utils import fractional_random_split\n",
    "from einops import rearrange, reduce\n",
    "from ema_pytorch import EMA\n",
    "from pytorch_lightning import Callback, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.strategies import DeepSpeedStrategy\n",
    "from torch import LongTensor, Tensor, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from audio_diffusion_pytorch import DiffusionModel, UNetV0, VDiffusion, VSampler\n",
    "import hydra\n",
    "\n",
    "from transformers import AutoModel\n",
    "import sys\n",
    "sys.path.insert(0, '/workspace/CLAP/src')\n",
    "\n",
    "from infer import infer_audio\n",
    "\n",
    "# Load environment variables from `.env`.\n",
    "dotenv.load_dotenv(override=True)\n",
    "log = utils.get_logger(__name__)\n",
    "\n",
    "sampling_rate = 48000\n",
    "length = 256\n",
    "wav_length = 2**18\n",
    "channels = 32\n",
    "path = \"/workspace/data\"\n",
    "strategy = \"deepspeed_stage_2\"\n",
    "num_workers = 9\n",
    "\n",
    "autoencoder = AutoModel.from_pretrained(\n",
    "    \"archinetai/dmae1d-ATC64-v2\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "@hydra.main()\n",
    "def main(config) -> None:\n",
    "    log.info(\"Disabling python warnings!\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Apply seed for reproducibility\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    \n",
    "    alltransformer = AllTransform(random_crop_size=wav_length, stereo=True, source_rate=sampling_rate, target_rate=sampling_rate)\n",
    "    def transform(wave):\n",
    "        x = alltransformer(wave)\n",
    "        y = x[None, :, :]\n",
    "        with torch.no_grad():\n",
    "            z = autoencoder.encode(y)\n",
    "            embed = infer_audio(wave)\n",
    "            return {\"waveform\": z.squeeze(), \"embedding\": embed}\n",
    "    \n",
    "    # Initialize datamodule\n",
    "    print(f\"Instantiating datamodule.\")\n",
    "    datamodule = Datamodule(\n",
    "        val_split=0.05,\n",
    "        batch_size=32,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        dataset=WAVDataset(\n",
    "            recursive=True,\n",
    "            sample_rate=sampling_rate,\n",
    "            transforms=transform,\n",
    "            path=path,\n",
    "            check_silence=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    print(f\"Instantiating model.\")\n",
    "    model = Model(\n",
    "        lr=1e-4,\n",
    "        lr_beta1=0.95,\n",
    "        lr_beta2=0.999,\n",
    "        lr_eps=1e-6,\n",
    "        lr_weight_decay=1e-3,\n",
    "        ema_beta=0.995,\n",
    "        ema_power=0.7,\n",
    "        model=DiffusionModel(\n",
    "            net_t=UNetV0, # The model type used for diffusion (U-Net V0 in this case)\n",
    "            in_channels=channels, # U-Net: number of input/output (audio) channels\n",
    "            channels=[128, 256, 512, 512, 1024, 1024], # U-Net: channels at each layer\n",
    "            factors=[1, 2, 2, 2, 2, 2], # U-Net: downsampling and upsampling factors at each layer\n",
    "            items=[2, 2, 2, 4, 8, 8], # U-Net: number of repeating items at each layer\n",
    "            attentions=[0, 0, 1, 1, 1, 1], # U-Net: attention enabled/disabled at each layer\n",
    "            attention_heads=12, # U-Net: number of attention heads per attention item\n",
    "            attention_features=64, # U-Net: number of attention features per attention item\n",
    "            diffusion_t=VDiffusion, # The diffusion method used\n",
    "            sampler_t=VSampler, # The diffusion sampler used\n",
    "            use_embedding_cfg=True, # U-Net: enables classifier free guidance\n",
    "            embedding_max_length=512, # U-Net: text embedding maximum length (default for T5-base)\n",
    "            embedding_features=512, # U-Net: text mbedding features (default for T5-base)\n",
    "            cross_attentions=[0, 0, 1, 1, 1, 1], # U-Net: cross-attention enabled/disabled at each layer\n",
    "            use_time_conditioning=False,\n",
    "            use_modulation=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize all callbacks (e.g. checkpoints, early stopping)\n",
    "    callbacks = []\n",
    "    callbacks.append(RichProgressBar())\n",
    "    callbacks.append(RichModelSummary(max_depth=2))\n",
    "    # callbacks.append(Checkpointer(output_dir=\"/workspace/output.ckpt\"))\n",
    "    callbacks.append(ModelCheckpoint(\n",
    "        verbose=True,\n",
    "        save_last=True,\n",
    "        monitor='valid_loss',\n",
    "        mode='min',\n",
    "        dirpath='/workspace',\n",
    "        filename='{epoch:02d}-{valid_loss:.3f}',\n",
    "        every_n_train_steps=100\n",
    "    ))\n",
    "    \n",
    "    # Initialize loggers (e.g. wandb)\n",
    "    loggers = []\n",
    "    loggers.append(\n",
    "        WandbLogger(\n",
    "            project=\"audio-diffusion\",\n",
    "            entity=\"tvergho1\",\n",
    "            job_type=\"train\",\n",
    "            group=\"\",\n",
    "            save_dir=\"/logs\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"Instantiating trainer.\")\n",
    "    trainer = Trainer(\n",
    "        callbacks=callbacks,\n",
    "        logger=loggers,\n",
    "        precision=32,\n",
    "        min_epochs=0,\n",
    "        max_epochs=-1,\n",
    "        enable_model_summary=False,\n",
    "        log_every_n_steps=1,\n",
    "        check_val_every_n_epoch=None,\n",
    "        val_check_interval=100,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        strategy=strategy,\n",
    "        gpus=1,\n",
    "        num_sanity_val_steps=0,\n",
    "        accumulate_grad_batches=4\n",
    "    )\n",
    "\n",
    "    # Send some parameters from config to all lightning loggers\n",
    "    print(\"Logging hyperparameters!\")\n",
    "    utils.log_hyperparameters(\n",
    "        config={\n",
    "            \"model\": \"diffusion\",\n",
    "            \"datamodule\": \"wav\",\n",
    "            \"trainer\": \"Trainer\"\n",
    "        },\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        trainer=trainer,\n",
    "        callbacks=callbacks,\n",
    "        logger=loggers,\n",
    "    )\n",
    "\n",
    "    print(\"Fitting!\")\n",
    "    trainer.fit(model=model, datamodule=datamodule, ckpt_path=\"/workspace/epoch=45-valid_loss=0.134.ckpt\")\n",
    "    # Make sure everything closed properly\n",
    "    print(\"Finalizing!\")\n",
    "    utils.finish(\n",
    "        config={},\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        trainer=trainer,\n",
    "        callbacks=callbacks,\n",
    "        logger=loggers,\n",
    "    )\n",
    "    print(f\"Best model ckpt at {trainer.log_dir}\")\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        lr_beta1: float,\n",
    "        lr_beta2: float,\n",
    "        lr_eps: float,\n",
    "        lr_weight_decay: float,\n",
    "        ema_beta: float,\n",
    "        ema_power: float,\n",
    "        model: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.lr_beta1 = lr_beta1\n",
    "        self.lr_beta2 = lr_beta2\n",
    "        self.lr_eps = lr_eps\n",
    "        self.lr_weight_decay = lr_weight_decay\n",
    "        self.model = model\n",
    "        self.model_ema = EMA(self.model, beta=ema_beta, power=ema_power)\n",
    "        self.train_loss = float('inf')\n",
    "        self.valid_loss = float('inf')\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.model.parameters()).device\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list(self.model.parameters()),\n",
    "            lr=self.lr,\n",
    "            betas=(self.lr_beta1, self.lr_beta2),\n",
    "            eps=self.lr_eps,\n",
    "            weight_decay=self.lr_weight_decay,\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        waveforms = batch\n",
    "        # loss = self.model(waveforms[\"waveform\"])\n",
    "        loss = self.model(x=waveforms[\"waveform\"], embedding=waveforms[\"embedding\"])\n",
    "        self.log(\"train_loss\", loss, rank_zero_only=True)\n",
    "        self.train_loss = loss\n",
    "        # Update EMA model and log decay\n",
    "        self.model_ema.update()\n",
    "        self.log(\"ema_decay\", self.model_ema.get_current_decay(), rank_zero_only=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        waveforms = batch\n",
    "        # loss = self.model_ema(waveforms[\"waveform\"])\n",
    "        loss = self.model_ema(x=waveforms[\"waveform\"], embedding=waveforms[\"embedding\"])\n",
    "        self.log(\"valid_loss\", loss, rank_zero_only=True)\n",
    "        self.valid_loss = loss\n",
    "        return loss\n",
    "\n",
    "class Datamodule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        *,\n",
    "        val_split: float,\n",
    "        batch_size: int,\n",
    "        num_workers: int,\n",
    "        pin_memory: bool = False,\n",
    "        **kwargs: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.val_split = val_split\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.data_train: Any = None\n",
    "        self.data_val: Any = None\n",
    "\n",
    "    def setup(self, stage: Any = None) -> None:\n",
    "        split = [1.0 - self.val_split, self.val_split]\n",
    "        self.data_train, self.data_val = fractional_random_split(self.dataset, split)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "class Checkpointer(Callback):\n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        self.best_loss = float('inf')\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        print(\"Saving checkpoint\")\n",
    "        if trainer.global_rank == 0:\n",
    "            print(f\"Valid_loss {pl_module.valid_loss} best loss {self.best_loss}\")\n",
    "            if pl_module.valid_loss < self.best_loss:\n",
    "                torch.save({\"model_state_dict\": pl_module.model.state_dict(), \"optimizer_dict\": trainer.optimizers[0].state_dict()}, self.output_dir)\n",
    "                self.best_loss = pl_module.valid_loss\n",
    "                print(\"Saved checkpoint\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572aa276-ad42-469f-ab72-4a19c90cc7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/audio-diffusion-pytorch-trainer/main/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/audio-diffusion-pytorch-trainer/main/utils.py\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from typing import Callable, List, Optional, Sequence\n",
    "\n",
    "import pkg_resources  # type: ignore\n",
    "import pytorch_lightning as pl\n",
    "import rich.syntax\n",
    "import rich.tree\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning import Callback\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "\n",
    "def get_logger(name=__name__) -> logging.Logger:\n",
    "    \"\"\"Initializes multi-GPU-friendly python command line logger.\"\"\"\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    # this ensures all logging levels get marked with the rank zero decorator\n",
    "    # otherwise logs would get multiplied for each GPU process in multi-GPU setup\n",
    "    for level in (\n",
    "        \"debug\",\n",
    "        \"info\",\n",
    "        \"warning\",\n",
    "        \"error\",\n",
    "        \"exception\",\n",
    "        \"fatal\",\n",
    "        \"critical\",\n",
    "    ):\n",
    "        setattr(logger, level, rank_zero_only(getattr(logger, level)))\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "log = get_logger(__name__)\n",
    "\n",
    "\n",
    "def extras(config: DictConfig) -> None:\n",
    "    \"\"\"Applies optional utilities, controlled by config flags.\n",
    "    Utilities:\n",
    "    - Ignoring python warnings\n",
    "    - Rich config printing\n",
    "    \"\"\"\n",
    "\n",
    "    # disable python warnings if <config.ignore_warnings=True>\n",
    "    if config.get(\"ignore_warnings\"):\n",
    "        log.info(\"Disabling python warnings! <config.ignore_warnings=True>\")\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # pretty print config tree using Rich library if <config.print_config=True>\n",
    "    if config.get(\"print_config\"):\n",
    "        log.info(\"Printing config tree with Rich! <config.print_config=True>\")\n",
    "        print_config(config, resolve=True)\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def print_config(\n",
    "    config: DictConfig,\n",
    "    print_order: Sequence[str] = (\n",
    "        \"datamodule\",\n",
    "        \"model\",\n",
    "        \"callbacks\",\n",
    "        \"logger\",\n",
    "        \"trainer\",\n",
    "    ),\n",
    "    resolve: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Prints content of DictConfig using Rich library and its tree structure.\n",
    "    Args:\n",
    "        config (DictConfig): Configuration composed by Hydra.\n",
    "        print_order (Sequence[str], optional): Determines in what order config components are printed.\n",
    "        resolve (bool, optional): Whether to resolve reference fields of DictConfig.\n",
    "    \"\"\"\n",
    "\n",
    "    style = \"dim\"\n",
    "    tree = rich.tree.Tree(\"CONFIG\", style=style, guide_style=style)\n",
    "\n",
    "    quee = []\n",
    "\n",
    "    for field in print_order:\n",
    "        quee.append(field) if field in config else log.info(\n",
    "            f\"Field '{field}' not found in config\"\n",
    "        )\n",
    "\n",
    "    for field in config:\n",
    "        if field not in quee:\n",
    "            quee.append(field)\n",
    "\n",
    "    for field in quee:\n",
    "        branch = tree.add(field, style=style, guide_style=style)\n",
    "\n",
    "        config_group = config[field]\n",
    "        if isinstance(config_group, DictConfig):\n",
    "            branch_content = OmegaConf.to_yaml(config_group, resolve=resolve)\n",
    "        else:\n",
    "            branch_content = str(config_group)\n",
    "\n",
    "        branch.add(rich.syntax.Syntax(branch_content, \"yaml\"))\n",
    "\n",
    "    rich.print(tree)\n",
    "\n",
    "    with open(\"config_tree.log\", \"w\") as file:\n",
    "        rich.print(tree, file=file)\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def log_hyperparameters(\n",
    "    config: DictConfig,\n",
    "    model: pl.LightningModule,\n",
    "    datamodule: pl.LightningDataModule,\n",
    "    trainer: pl.Trainer,\n",
    "    callbacks: List[pl.Callback],\n",
    "    logger: List[pl.loggers.Logger],\n",
    ") -> None:\n",
    "    \"\"\"Controls which config parts are saved by Lightning loggers.\n",
    "    Additionaly saves:\n",
    "    - number of model parameters\n",
    "    \"\"\"\n",
    "\n",
    "    if not trainer.logger:\n",
    "        return\n",
    "\n",
    "    hparams = {}\n",
    "\n",
    "    # choose which parts of hydra config will be saved to loggers\n",
    "    hparams[\"model\"] = config[\"model\"]\n",
    "\n",
    "    # save number of model parameters\n",
    "    hparams[\"model/params/total\"] = sum(p.numel() for p in model.parameters())\n",
    "    hparams[\"model/params/trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad\n",
    "    )\n",
    "    hparams[\"model/params/non_trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if not p.requires_grad\n",
    "    )\n",
    "\n",
    "    hparams[\"datamodule\"] = config[\"datamodule\"]\n",
    "    hparams[\"trainer\"] = config[\"trainer\"]\n",
    "\n",
    "    if \"seed\" in config:\n",
    "        hparams[\"seed\"] = config[\"seed\"]\n",
    "    if \"callbacks\" in config:\n",
    "        hparams[\"callbacks\"] = config[\"callbacks\"]\n",
    "\n",
    "    hparams[\"pacakges\"] = get_packages_list()\n",
    "\n",
    "    # send hparams to all loggers\n",
    "    trainer.logger.log_hyperparams(hparams)\n",
    "\n",
    "\n",
    "def finish(\n",
    "    config: DictConfig,\n",
    "    model: pl.LightningModule,\n",
    "    datamodule: pl.LightningDataModule,\n",
    "    trainer: pl.Trainer,\n",
    "    callbacks: List[pl.Callback],\n",
    "    logger: List[pl.loggers.Logger],\n",
    ") -> None:\n",
    "    \"\"\"Makes sure everything closed properly.\"\"\"\n",
    "\n",
    "    # without this sweeps with wandb logger might crash!\n",
    "    for lg in logger:\n",
    "        if isinstance(lg, pl.loggers.wandb.WandbLogger):\n",
    "            import wandb\n",
    "\n",
    "            wandb.finish()\n",
    "\n",
    "\n",
    "def get_packages_list() -> List[str]:\n",
    "    return [f\"{p.project_name}=={p.version}\" for p in pkg_resources.working_set]\n",
    "\n",
    "\n",
    "def retry_if_error(fn: Callable, num_attemps: int = 10):\n",
    "    for attempt in range(num_attemps):\n",
    "        try:\n",
    "            return fn()\n",
    "        except:\n",
    "            print(f\"Retrying, attempt {attempt+1}\")\n",
    "            pass\n",
    "    return fn()\n",
    "\n",
    "\n",
    "class SavePytorchModelAndStopCallback(Callback):\n",
    "    def __init__(self, path: str, attribute: Optional[str] = None):\n",
    "        self.path = path\n",
    "        self.attribute = attribute\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        model, path = pl_module, self.path\n",
    "        if self.attribute is not None:\n",
    "            assert_message = \"provided model attribute not found in pl_module\"\n",
    "            assert hasattr(pl_module, self.attribute), assert_message\n",
    "            model = getattr(\n",
    "                pl_module, self.attribute, hasattr(pl_module, self.attribute)\n",
    "            )\n",
    "        # Make dir if not existent\n",
    "        os.makedirs(os.path.split(path)[0], exist_ok=True)\n",
    "        # Save model\n",
    "        torch.save(model, path)\n",
    "        log.info(f\"PyTorch model saved at: {path}\")\n",
    "        # Stop trainer\n",
    "        trainer.should_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39766fac-83f0-4083-b7a9-80e9aa950de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CLAP'...\n",
      "remote: Enumerating objects: 4010, done.\u001b[K\n",
      "remote: Counting objects: 100% (661/661), done.\u001b[K\n",
      "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
      "remote: Total 4010 (delta 457), reused 611 (delta 431), pack-reused 3349\u001b[K\n",
      "Receiving objects: 100% (4010/4010), 6.69 MiB | 953.00 KiB/s, done.\n",
      "Resolving deltas: 100% (2990/2990), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LAION-AI/CLAP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3aea41e-fa7d-451b-bfd1-35cdf4ca1195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: torchlibrosa in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 3)) (0.0.9)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 4)) (6.1.1)\n",
      "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 5)) (0.1.7)\n",
      "Requirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 6)) (0.2.33)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 7)) (3.2)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 8)) (0.13.10)\n",
      "Requirement already satisfied: llvmlite in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 9)) (0.39.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 10)) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 11)) (1.2.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 12)) (1.5.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 13)) (3.8.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 14)) (4.64.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 15)) (2022.10.31)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r ./CLAP/requirements.txt (line 16)) (4.26.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r ./CLAP/requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (0.56.4)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (0.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r ./CLAP/requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r ./CLAP/requirements.txt (line 4)) (0.2.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset->-r ./CLAP/requirements.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (8.1.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (4.22.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (2.28.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (5.9.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (3.1.31)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r ./CLAP/requirements.txt (line 8)) (67.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ./CLAP/requirements.txt (line 11)) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r ./CLAP/requirements.txt (line 12)) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r ./CLAP/requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./CLAP/requirements.txt (line 16)) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./CLAP/requirements.txt (line 16)) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./CLAP/requirements.txt (line 16)) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ./CLAP/requirements.txt (line 16)) (23.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r ./CLAP/requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->-r ./CLAP/requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=1.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r ./CLAP/requirements.txt (line 8)) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r ./CLAP/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3850ef7-24e1-4175-b923-cb8aa29e87ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./CLAP/src/infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./CLAP/src/infer.py\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from open_clip import create_model\n",
    "from training.data import get_audio_features\n",
    "from training.data import int16_to_float32, float32_to_int16\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "precision = 'fp32'\n",
    "amodel = 'HTSAT-tiny' # or 'PANN-14'\n",
    "tmodel = 'roberta' # the best text encoder in our training\n",
    "enable_fusion = True # False if you do not want to use the fusion model\n",
    "fusion_type = 'aff_2d'\n",
    "pretrained = \"/workspace/clap.pt\" # the checkpoint name, the unfusion model can also be loaded.\n",
    "pretrained_audio = \"/workspace/HTSAT2.ckpt\"\n",
    "\n",
    "model, model_cfg = create_model(\n",
    "    amodel_name=amodel,\n",
    "    tmodel_name=tmodel,\n",
    "    pretrained=pretrained,\n",
    "    pretrained_audio=pretrained_audio,\n",
    "    precision=precision,\n",
    "    device=device,\n",
    "    enable_fusion=enable_fusion,\n",
    "    fusion_type=fusion_type\n",
    ")\n",
    "\n",
    "def infer_audio(waveform):\n",
    "    # load the waveform of the shape (T,), should resample to 48000\n",
    "    # librosa_waveform, sr = librosa.load(\"/workspace/data/000002.wav\", sr=48000) \n",
    "    # librosa_waveform = int16_to_float32(float32_to_int16(librosa_waveform))\n",
    "    # librosa_waveform = torch.from_numpy(librosa_waveform).float()\n",
    "    \n",
    "    audio_waveform = torch.mean(waveform, dim=0).float()\n",
    "    audio_dict = {}\n",
    "\n",
    "    # the 'fusion' truncate mode can be changed to 'rand_trunc' if run in unfusion mode\n",
    "    audio_dict = get_audio_features(\n",
    "        audio_dict, audio_waveform, 480000, \n",
    "        data_truncating='fusion', \n",
    "        data_filling='repeatpad',\n",
    "        audio_cfg=model_cfg['audio_cfg']\n",
    "    )\n",
    "    # can send a list to the model, to process many audio tracks in one time (i.e. batch size)\n",
    "    audio_embed = model.get_audio_embedding([audio_dict])\n",
    "    # print(\"Embedded\", audio_embed.size())\n",
    "    return audio_embed\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    infer_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acbbd5f0-15eb-48ad-81c8-08abb8fc19a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/audio-diffusion-pytorch-trainer/test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/audio-diffusion-pytorch-trainer/test.py\n",
    "import sys\n",
    "import torchaudio\n",
    "sys.path.insert(0, '/workspace/CLAP/src')\n",
    "\n",
    "from infer import infer_audio\n",
    "\n",
    "waveform, rate = torchaudio.load(\"/workspace/data/000002.wav\")\n",
    "embed = infer_audio(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84781b-31fb-4e2d-b593-a004ca66d001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall torchlibrosa --yes\n",
    "!pip install 'torchlibrosa @ git+https://github.com/azuwis/torchlibrosa.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3cba1-7638-42d7-beee-234e2c713fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python audio-diffusion-pytorch-trainer/train_custom.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
